{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import nbformat\n",
    "from nbconvert import HTMLExporter\n",
    "from nbconvert.preprocessors import ExecutePreprocessor, CellExecutionError\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "import sys\n",
    "import platform\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../accy575-sp-2023/04-conference-call-submissions\\\\anacondas_324892_7959414_ZJ 04-conference-calls.ipynb',\n",
       " '../../accy575-sp-2023/04-conference-call-submissions\\\\ancillaries_334459_7927663_ConferenceCalls_Ancillaries.ipynb',\n",
       " '../../accy575-sp-2023/04-conference-call-submissions\\\\df_324476_7927252_04-conference-calls_df-1.ipynb']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpaths = glob.glob('../../accy575-sp-2023/04-conference-call-submissions/*.ipynb')\n",
    "fpaths = list(filter(lambda f: not f.endswith('-graded.ipynb'), fpaths))\n",
    "fpaths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = glob.glob('test-notebooks/exercise-05/*.ipynb')\n",
    "fpaths = list(filter(lambda f: not f.endswith('-graded.ipynb'), fpaths))\n",
    "fpaths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = glob.glob('test-notebooks/05-yellow*-SOLUTION.ipynb')\n",
    "fpaths = list(filter(lambda f: not f.endswith('-graded.ipynb'), fpaths))\n",
    "fpaths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = glob.glob('../submissions/case-study-03-test/*.ipynb')\n",
    "fpaths = list(filter(lambda f: not f.endswith('-graded.ipynb'), fpaths))\n",
    "fpaths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "Grading ../../accy575-sp-2023/04-conference-call-submissions\\anacondas_324892_7959414_ZJ 04-conference-calls.ipynb\n",
      "Complete\n",
      "=============================\n",
      "Grading ../../accy575-sp-2023/04-conference-call-submissions\\ancillaries_334459_7927663_ConferenceCalls_Ancillaries.ipynb\n",
      "Complete\n",
      "=============================\n",
      "Grading ../../accy575-sp-2023/04-conference-call-submissions\\df_324476_7927252_04-conference-calls_df-1.ipynb\n",
      "Complete\n",
      "=============================\n",
      "Grading ../../accy575-sp-2023/04-conference-call-submissions\\excellent_65151_7990503_04-conference-calls_Excellent.ipynb\n",
      "Complete\n",
      "=============================\n",
      "Grading ../../accy575-sp-2023/04-conference-call-submissions\\get_an_a_323576_7927319_04-conference-calls-get_an_A.ipynb\n",
      "Complete\n",
      "=============================\n",
      "Grading ../../accy575-sp-2023/04-conference-call-submissions\\group_x_6126_7948838_04-conference-calls.ipynb\n",
      "Complete\n",
      "=============================\n",
      "Grading ../../accy575-sp-2023/04-conference-call-submissions\\may_323193_7937623_conference-calls-May (1).ipynb\n",
      "Complete\n",
      "=============================\n",
      "Grading ../../accy575-sp-2023/04-conference-call-submissions\\numpy_321946_7959220_Group_Numpy_04-conference-calls.ipynb\n",
      "Complete\n",
      "=============================\n",
      "Grading ../../accy575-sp-2023/04-conference-call-submissions\\pandas_330521_7931922_04-conference-calls.ipynb\n",
      "Complete\n",
      "=============================\n",
      "Grading ../../accy575-sp-2023/04-conference-call-submissions\\pythons_3369_7875719_04-conference-calls.ipynb\n",
      "Complete\n",
      "=============================\n",
      "Grading ../../accy575-sp-2023/04-conference-call-submissions\\solid_312038_7980972_Solid conference calls FINAL.ipynb\n",
      "Complete\n",
      "=============================\n",
      "Grading ../../accy575-sp-2023/04-conference-call-submissions\\square_328074_7933517_04-conference-calls.ipynb\n",
      "Complete\n",
      "=============================\n",
      "Grading ../../accy575-sp-2023/04-conference-call-submissions\\teletubbies_296476_7957113_04-conference-calls.ipynb\n",
      "Complete\n",
      "=============================\n",
      "Grading ../../accy575-sp-2023/04-conference-call-submissions\\thosh_7733_7928169_04-conference-calls.ipynb\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import lambdagrader\n",
    "\n",
    "graded_results = []\n",
    "\n",
    "for notebook_path in fpaths:\n",
    "    try:\n",
    "        print('=============================')\n",
    "        nb = nbformat.read(notebook_path, as_version=4)\n",
    "        \n",
    "        test_cases_hash = lambdagrader.get_test_cases_hash(nb)\n",
    "        \n",
    "        lambdagrader.preprocess_test_case_cells(nb)\n",
    "        lambdagrader.add_grader_scripts(nb)\n",
    "\n",
    "        p = Path(notebook_path)\n",
    "        filestem = p.name\n",
    "        \n",
    "        print(f'Grading {notebook_path}')\n",
    "        \n",
    "        ep = ExecutePreprocessor(\n",
    "            timeout=1800,\n",
    "            kernel_name='python3',\n",
    "            allow_errors=True\n",
    "        )\n",
    "        ep.preprocess(nb)\n",
    "        \n",
    "        # save graded notebook\n",
    "        converted_notebook_path = notebook_path.replace('.ipynb', '-graded.ipynb')\n",
    "        with open(converted_notebook_path, mode='w', encoding='utf-8') as f:\n",
    "            nbformat.write(nb, f)\n",
    "        \n",
    "        # running the notebook will store the graded result to a JSON file\n",
    "        # rename graded result JSON file\n",
    "        graded_result_json_path = notebook_path.replace('.ipynb', '-result.json')\n",
    "        shutil.move('lambdagrader-result.json', graded_result_json_path)\n",
    "        \n",
    "        # read graded result to generate a summary\n",
    "        with open(graded_result_json_path, mode='r') as f:\n",
    "            graded_result = json.load(f)\n",
    "        \n",
    "        # add filename\n",
    "        # we add it here instead of trying to add it within the Jupyter notebook\n",
    "        # because it is tricky to grab the current file name inside a Jupyter kernel\n",
    "        graded_result['filename'] = Path(notebook_path).name\n",
    "        \n",
    "        # MD5 hash of the submitted Jupyter notebook file\n",
    "        # this can be used to detect duplicate submission to prevent unnecessary re-grading\n",
    "        with open(notebook_path, 'rb') as f:\n",
    "            graded_result['submission_notebook_hash'] = hashlib.md5(f.read()).hexdigest()\n",
    "        \n",
    "        # MD5 hash of test cases code\n",
    "        # this helps us to identify any potential cases\n",
    "        # where a learner has modified or deleted the test cases code cell\n",
    "        graded_result['test_cases_hash'] = test_cases_hash\n",
    "        \n",
    "        # store Python version and platform used to run the notebook\n",
    "        graded_result['grader_python_version'] = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n",
    "        graded_result['grader_platform'] = platform.platform()\n",
    "\n",
    "        # save updated JSON to file\n",
    "        with open(graded_result_json_path, 'w') as f:\n",
    "            json.dump(graded_result, f, indent=2)\n",
    "            \n",
    "        # clean up notebook\n",
    "        lambdagrader.remove_grader_scripts(nb)\n",
    "        lambdagrader.add_graded_result(nb, graded_result)\n",
    "           \n",
    "        # extract user code to a Python file\n",
    "        extracted_user_code = lambdagrader.extract_user_code_from_notebook(nb)\n",
    "        extracted_code_path = notebook_path.replace('.ipynb', '_user_code.py')\n",
    "        \n",
    "        with open(extracted_code_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(extracted_user_code)\n",
    "        \n",
    "        # store graded result to HTML\n",
    "        filestem = Path(notebook_path).name\n",
    "        graded_html_path = notebook_path.replace('.ipynb', '-graded.html')\n",
    "        lambdagrader.save_graded_notebook_to_html(\n",
    "            nb,\n",
    "            html_title=filestem,\n",
    "            output_path=graded_html_path\n",
    "        )\n",
    "        \n",
    "        # LOCAL ENVIRONMENT ONLY\n",
    "        # the Lambda handler only processes one file instead of\n",
    "        # running a batch\n",
    "        # the code below generates a CSV to show results for multiple files\n",
    "        # get text summary of user's graded result\n",
    "        text_summary = lambdagrader.generate_text_summary(graded_result)\n",
    "        \n",
    "        result_summary = graded_result.copy()\n",
    "        result_summary['text_summary'] = text_summary\n",
    "        del result_summary['results']\n",
    "        graded_results.append(result_summary)\n",
    "        \n",
    "        print(f'Complete')\n",
    "    except Exception as e:\n",
    "        print(f'Error while grading {notebook_path}')\n",
    "        print('-----------------------------')\n",
    "        print(e)\n",
    "        \n",
    "df_summary = pd.DataFrame(graded_results)\n",
    "\n",
    "df_summary.to_csv(\n",
    "    f\"graded_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
    "    index=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copydetect import CopyDetector\n",
    "detector = CopyDetector(test_dirs=[\"../submissions/exercise-07\"], extensions=[\"py\"])\n",
    "detector.run()\n",
    "detector.generate_html_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lambdagrader import *\n",
    "\n",
    "notebook_path = '../notebooks\\\\case-study-04-rideshare-trips-SOLUTION.ipynb'\n",
    "nb = nbformat.read(notebook_path, as_version=4)\n",
    "\n",
    "tcs = extract_test_cases_metadata_from_notebook(nb)\n",
    "\n",
    "s = 0\n",
    "\n",
    "for o in tcs:\n",
    "    s += o['points']\n",
    "    \n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lambdagrader\n",
    "\n",
    "html_path = 'test_notebook.html'\n",
    "\n",
    "with open(html_path, mode='r', encoding='utf-8') as f:\n",
    "    html_doc = f.read()\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "    elements = soup.find_all('div', class_='jp-CodeCell')\n",
    "    # print(elements[:3])\n",
    "    \n",
    "    tc_counts = {}\n",
    "    \n",
    "    for el in elements:\n",
    "        cell_code = el.find('div', class_='jp-Editor').getText().strip()\n",
    "        \n",
    "        tc = lambdagrader.extract_test_case_metadata_from_cell(cell_code)\n",
    "        \n",
    "        if tc:\n",
    "            if tc['test_case'] not in tc_counts:\n",
    "                tc_counts[tc['test_case']] = 0\n",
    "            \n",
    "            tc_counts[tc['test_case']] += 1\n",
    "            \n",
    "            print(tc)\n",
    "            el['id'] = f\"{tc['test_case']}_id{tc_counts[tc['test_case']]}\"\n",
    "    \n",
    "\n",
    "p = Path(html_path)\n",
    "new_filename = f'{p.stem}_anchored{p.suffix}'\n",
    "\n",
    "with open(new_filename, mode='w+', encoding='utf-8') as f:\n",
    "    f.write(soup.prettify())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
